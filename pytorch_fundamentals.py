# -*- coding: utf-8 -*-
"""pytorch_fundamentals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FtB8Rdz4_Ll5mbPNseJl0Uln0C8SPkRg
"""

import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
print(torch.__version__)

"""##Introduction to tensors
## (use !nvidia-smi if needed)

"""

import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
print(torch.__version__)

# scalar
scalar = torch.tensor(7)
scalar

scalar.ndim

scalar.item()

#vector
vector=torch.tensor([7,7])
vector

vector.ndim

vector.shape

#Matrix
matrix=torch.tensor([[7,8],[9,10]])
matrix

matrix.ndim

matrix[0]

matrix.shape

#tensor
tensor=torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[1,2,5],[3,4,7],[5,6,9]]])
tensor

tensor.ndim

tensor.shape

tensor[0]

"""### Random Tensors

```start with rand no. -> look at data ->update rand no. -> look at data ->update rand no.```


"""

# create rand. tensor of size(3,4)
random_tensor=torch.rand(3,4)
random_tensor

# tensor with similar shape of image tensor
# height , width , color channels
random_img=torch.rand(size=(224,224,3))
random_img.ndim , random_img.shape

#zeros and ones
zero=torch.zeros(size=(3,4))
zero

# mask alll no.s in random tensor , just multiply
zero*random_tensor

ones = torch.ones(size=(3,5))
ones

#default types
ones.dtype

random_tensor.dtype

"""## range of tensors"""

torch.range(0,10)

torch.arange(0,10)

var = torch.arange(start=0,end=1000,step=77)
var

vari = torch.arange(start=0,end=10,step=1)
vari

# creating tensors like , when shape need not be mentioned
ten_zeros=torch.zeros_like(input=vari)
ten_zeros

"""## Tensor datatypes"""

# flaot 32 data type
float_32_tensor=torch.tensor([3.0,6.0,9.0],dtype=None,device=None,requires_grad=False)
float_32_tensor

#default is flaot  , flaot32 is basically single precision floating point
float_32_tensor.dtype

float_16_tensor=float_32_tensor.type(torch.float16)
float_16_tensor

#always doesnot work ,especially when datatype isn't same while training
float_32_tensor * float_16_tensor

# create rand tensor and get info
some_tensor = torch.rand(3,4)
some_tensor

print(some_tensor)
print(f"data type of tensor is : {some_tensor.dtype}")
print(f"shape of tensor is : {some_tensor.shape}")
print(f"device tensor is on : {some_tensor.device}")

"""##Manipulating tensors
addn,sub,multi,div,matrix multi
"""

tensor=torch.tensor([1,2,3])
tensor+10

tensor*10-2

tensor/10
tensor

torch.mul(tensor,10)

torch.add(tensor,2)

"""## Matrix multiplication

2 ways to do multiplication
1.element wise
2.matrix multiplication
"""

# element wise
tensor*tensor

# matrix multiplication
torch.matmul(tensor,tensor)

tensor1=torch.tensor([[1,2],[3,4],[5,6]])
tensor2=torch.tensor([[7,8,9],[9,10,11]])
torch.matmul(tensor1,tensor2)

tensor3=torch.tensor([[1,2],[3,4],[5,6]])
torch.mul(tensor1,tensor3)

"""## Dealing with shape errors in matrix multiplication"""

tensor_a=torch.rand(3,2)
tensor_b=torch.rand(3,2)

torch.mm(tensor_a,tensor_b)
# instead of using matmul we can aldo use mm

# to fix isssues , lets use transpose
tensor_b=tensor_b.T
torch.mm(tensor_a,tensor_b)

tensor_b.shape

"""## therefore,need to write as tensor.mm(tensor_a,tensor_b.T)

## finding min , max , mean , sum etc (tensor aggregation)
"""

x=torch.arange(0,100,10)
x

torch.min(x),x.min(),torch.max(x),x.max()

# finding mean
torch.mean(x.type(torch.float32)),x.type(torch.float32).mean()

# positional min and max ,we get the index where max/min occurs
torch.argmax(x) , x.argmax(),torch.argmin(x),x.argmin()

x[9],x[0]

"""## Reshaping,stacking , squeezing , unsqueezing"""

x=torch.arange(1. , 10.)
x , x.shape

x_reshaped=x.reshape(1,9)
x_reshaped , x_reshaped.shape

x_reshaped=x.reshape(9,1)
x_reshaped , x_reshaped.shape

x_reshaped=x.reshape(3,3)
x_reshaped , x_reshaped.shape

# change the view
#view shares the same memory ,its like a copy
z=x.view(1,9)
z ,z.shape

# changing z changes x
z[:,0]=5
z,x

# stack tensors
x_stacked=torch.stack([x,x,x,x],dim=0
)
x_stacked

# squeeze and unsqueeze
x_reshaped2=x.reshape(1,9)
x_squeezed=torch.squeeze(x_reshaped2)
x_squeezed

# its shape previously is (1,9) but now it is (9)
x_squeezed.shape

# unsqueeze adds the dimension back
x_unsqueezed=torch.unsqueeze(x_squeezed,dim=0)
x_unsqueezed , x_unsqueezed.shape

# permute - rearranges dimensions of target tensor in a specified order
x_original = torch.rand(size=(224,224,3))
# permute now , permute returns a view
x_permuted=x_original.permute(2,0,1)
x_original.shape,x_permuted.shape

# Indexing , similar to how we do it in numpy
x=torch.arange(1,10).reshape(1,3,3)
x,x.shape

# lets index on new tensor
x[0] , x[0][0]

x[0][0][0] , x[0][0][1]

# use ":" to select all of a target dimension
x[: , 0] , x[:,1,:] , x[:,:,1] , x[0,2,2]

"""# numpy is a papular python numerical com[pputing library ,
# so pytorch has functionality to interact with it
# data in numpy to tensor in pytorch
# use `torch.from_numpy(ndarray)`
# pytorch to numpy , use `torch.Tensor.numpy()`



"""

# numpy to tensor
import torch
import numpy as np
array=np.arange(1.0,10.0)
tensor=torch.from_numpy(array).type(torch.float32)
# if we had not specified float32 , pytoch would directly inherit float 64 which is default datatype for numpy
array , tensor
# if we change array , tensor will not affect

# tensor to numpy
tensor = torch.ones(7)
NUMPY_TENSOR = tensor.numpy()
tensor , NUMPY_TENSOR

"""## Reproducibility(random out of random)

In short , how a nueral network runs is

`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`

to reduce randomness , we us concept of **random seed**

what it does is flavour the randomness

"""

# create 2 rand tensors
random_tensor_A=torch.rand(3,4)
random_tensor_B=torch.rand(3,4)
print(random_tensor_A)
print(random_tensor_B)
print(random_tensor_A==random_tensor_B)

# lets make random but reproducable tensors
torch.manual_seed(42)
random_tensor_C=torch.rand(3,4)
torch.manual_seed(42)
random_tensor_D=torch.rand(3,4)
print(random_tensor_C)
print(random_tensor_D)
print(random_tensor_C==random_tensor_D)



"""# Task
Okay, great! Let's proceed with the plan.

First, let's create a new GitHub repository. Please follow these steps:

1.  Go to [GitHub](https://github.com/Srishanth-Rao).
2.  On the left sidebar, click on the green "New" button (or click the "+" icon in the top right corner and select "New repository").
3.  For the "Repository name", you can use something descriptive like `Pytorch_Tensor_Basics`.
4.  You can add an optional description.
5.  Choose whether you want the repository to be "Public" or "Private". For sharing this notebook, "Public" is usually preferred.
6.  Check the box to "Add a README file".
7.  Click the green "Create repository" button.

Once you've created the repository, please let me know, and we'll move on to saving and downloading your Colab notebook.

## Create GitHub Repository

### Subtask:
Create a new GitHub repository on your account.

### Subtask:
Create a new GitHub repository on your account.

#### Instructions
1. Go to https://github.com/Srishanth-Rao.
2. On the left sidebar, click on the green "New" button (or click the "+" icon in the top right corner and select "New repository").
3. For the "Repository name", use `Pytorch_Tensor_Basics`.
4. Add an optional description if you wish.
5. Choose "Public" for the repository visibility.
6. Check the box to "Add a README file".
7. Click the green "Create repository" button.

### Subtask:
Create a new GitHub repository on your account.

#### Instructions
1. Go to https://github.com/Srishanth-Rao.
2. On the left sidebar, click on the green "New" button (or click the "+" icon in the top right corner and select "New repository").
3. For the "Repository name", use `Pytorch_Tensor_Basics`.
4. Add an optional description if you wish.
5. Choose "Public" for the repository visibility.
6. Check the box to "Add a README file".
7. Click the green "Create repository" button.

## Save and Download Notebook

### Subtask:
Save your current Colab notebook and download it as an '.ipynb' file.

## Save and Download Notebook

### Subtask:
Save your current Colab notebook and download it as an '.ipynb' file.

#### Instructions
1. Go to 'File' in the top left corner of the Colab interface.
2. Select 'Save a copy in GitHub' to ensure your latest changes are saved before downloading.
3. After saving, go to 'File' again.
4. Select 'Download' and then choose 'Download .ipynb'.

## Upload Notebook to GitHub

### Subtask:
Upload the downloaded '.ipynb' file to your newly created GitHub repository.

## Upload Notebook to GitHub

### Subtask:
Upload the downloaded '.ipynb' file to your newly created GitHub repository.

#### Instructions
1. Go to your newly created GitHub repository (e.g., `Pytorch_Tensor_Basics`).
2. Click on the 'Add file' button and select 'Upload files'.
3. Drag and drop your downloaded Colab notebook file (ending with `.ipynb`) into the upload area, or click 'choose your files' to select it.
4. Add a commit message in the 'Commit changes' section (e.g., "Add Pytorch Tensor Basics notebook").
5. Click the green 'Commit changes' button to finalize the upload.

## Upload Notebook to GitHub

### Subtask:
Upload the downloaded '.ipynb' file to your newly created GitHub repository.

#### Instructions
1. Go to your newly created GitHub repository (e.g., `Pytorch_Tensor_Basics`).
2. Click on the 'Add file' button and select 'Upload files'.
3. Drag and drop your downloaded Colab notebook file (ending with `.ipynb`) into the upload area, or click 'choose your files' to select it.
4. Add a commit message in the 'Commit changes' section (e.g., "Add Pytorch Tensor Basics notebook").
5. Click the green 'Commit changes' button to finalize the upload.

## Final Task

### Subtask:
Confirm that the notebook has been successfully uploaded to your GitHub repository.

## Summary:

### Q&A
**Q: Has the notebook been successfully uploaded to the GitHub repository?**
A: The process provided step-by-step instructions for the user to upload the notebook to their GitHub repository. However, the successful completion of the upload itself is an external action performed by the user and was not programmatically confirmed within this solving process.

### Data Analysis Key Findings
*   The overall task was broken down into three subtasks: creating a GitHub repository, saving/downloading the Colab notebook, and uploading the notebook to GitHub.
*   For all subtasks, the solution involved generating clear, step-by-step instructions in markdown format for the user to perform external actions.
*   A new GitHub repository was specified to be created with the name `Pytorch_Tensor_Basics` and set to "Public" visibility with a README file.
*   The Colab notebook was instructed to be saved first, then downloaded as an `.ipynb` file.
*   Instructions were provided for uploading the downloaded `.ipynb` file to the created GitHub repository, including guidance on selecting "Upload files" and committing changes with a message.
*   Each subtask was considered successfully completed upon the provision of these detailed instructions, acknowledging that the actual execution depended on user action.

### Insights or Next Steps
*   The current workflow is highly reliant on manual user execution for external actions like GitHub repository creation and file uploads.
*   For future iterations, consider exploring methods for programmatic verification of external actions (e.g., using GitHub APIs to confirm repository and file existence) to enhance task automation and robustness.
"""